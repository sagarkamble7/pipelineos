# discovered_companies:
# {
#   "_id": {
#     "$oid": "68890042ada3746b1bacf2a5"
#   },
#   "name": "Flowcast AI solutions",
#   "domain": "flowcast.ai",
#   "industries": [
#     "Artificial Intelligence",
#     "FinTech"
#   ],
#   "employee_count_estimate": {
#     "min": 50,
#     "max": 200
#   },
#   "hq_location": {
#     "city": "San Francisco",
#     "country": "USA"
#   },
#   "founded_year": 2019,
#   "tech_stack": [
#     "Python",
#     "AWS",
#     "LangChain"
#   ],
#   "social_metrics": {
#     "followers": {
#       "linkedin": 1500,
#       "twitter": 600
#     }
#   },
#   "source_urls": [
#     "https://linkedin.com/company/flowcast-ai"
#   ],
#   "last_scraped": {
#     "$date": "2025-07-27T11:00:00.000Z"
#   },
#   "last_scored": null,
#   "last_vectorized": {
#     "$date": "2025-08-04T10:32:19.574Z"
#   },
#   "changed_at": {
#     "$date": "2025-08-03T10:00:00.000Z"
#   },
#   "icp_id": {
#     "$oid": "64c4a23b69a84f2b0b789cde"
#   },
#   "icp_version": 1
# }

# -------------------------------------

# {
#   "_id": {
#     "$oid": "68890042ada3746b1bacf2a6"
#   },
#   "name": "SynthAI Inc.",
#   "domain": "ssynthai.io",
#   "industries": [
#     "Artificial Intelligence",
#     "SaaS"
#   ],
#   "employee_count_estimate": {
#     "min": 20,
#     "max": 80
#   },
#   "hq_location": {
#     "city": "Toronto",
#     "country": "Canada"
#   },
#   "founded_year": 2021,
#   "tech_stack": [
#     "Python",
#     "GCP",
#     "HuggingFace"
#   ],
#   "social_metrics": {
#     "followers": {
#       "linkedin": 700,
#       "twitter": 1200
#     }
#   },
#   "source_urls": [
#     "https://linkedin.com/company/synthai"
#   ],
#   "last_scraped": {
#     "$date": "2025-07-28T08:30:00.000Z"
#   },
#   "last_scored": {
#     "$date": "2025-07-27T12:00:00.000Z"
#   },
#   "last_vectorized": {
#     "$date": "2025-08-04T10:32:19.593Z"
#   },
#   "changed_at": {
#     "$date": "2025-07-27T13:00:00.000Z"
#   },
#   "icp_id": {
#     "$oid": "64c4a23b69a84f2b0b789cdf"
#   },
#   "icp_version": 1
# }

# -------------------------------------

# {
#   "_id": {
#     "$oid": "68890042ada3746b1bacf2a7"
#   },
#   "name": "DocStream AI",
#   "domain": "ddocstream.com",
#   "industries": [
#     "SaaS",
#     "Document Management"
#   ],
#   "employee_count_estimate": {
#     "min": 100,
#     "max": 250
#   },
#   "hq_location": {
#     "city": "Austin",
#     "country": "USA"
#   },
#   "founded_year": 2016,
#   "tech_stack": [
#     "Node.js",
#     "MongoDB",
#     "AWS"
#   ],
#   "social_metrics": {
#     "followers": {
#       "linkedin": 300,
#       "twitter": 90
#     }
#   },
#   "source_urls": [
#     "https://linkedin.com/company/docstream"
#   ],
#   "last_scraped": {
#     "$date": "2025-07-25T09:00:00.000Z"
#   },
#   "last_scored": {
#     "$date": "2025-07-26T09:30:00.000Z"
#   },
#   "last_vectorized": {
#     "$date": "2025-08-04T10:32:19.613Z"
#   },
#   "changed_at": {
#     "$date": "2025-07-25T14:00:00.000Z"
#   },
#   "icp_id": {
#     "$oid": "64c4a23b69a84f2b0b789ce0"
#   },
#   "icp_version": 1
# }

# -----------------------

# {
#   "_id": {
#     "$oid": "68890042ada3746b1bacf2a8"
#   },
#   "name": "NeoGen Cloud",
#   "domain": "neogencloud.com",
#   "industries": [
#     "Cloud",
#     "AI"
#   ],
#   "employee_count_estimate": {
#     "min": 5,
#     "max": 30
#   },
#   "hq_location": {
#     "city": "Vancouver",
#     "country": "Canada"
#   },
#   "founded_year": 2022,
#   "tech_stack": [
#     "Azure",
#     "Docker",
#     "LangChain"
#   ],
#   "social_metrics": {
#     "followers": {
#       "linkedin": 250,
#       "twitter": 50
#     }
#   },
#   "source_urls": [
#     "https://linkedin.com/company/neogencloud"
#   ],
#   "last_scraped": {
#     "$date": "2025-07-29T09:00:00.000Z"
#   },
#   "last_scored": null,
#   "last_vectorized": {
#     "$date": "2025-08-04T10:32:19.630Z"
#   },
#   "changed_at": {
#     "$date": "2025-07-29T08:50:00.000Z"
#   },
#   "icp_id": {
#     "$oid": "64c4a23b69a84f2b0b789ce1"
#   },
#   "icp_version": 2
# }


# --------------------------

# {
#   "_id": {
#     "$oid": "68890042ada3746b1bacf2a9"
#   },
#   "name": "Retico AI",
#   "domain": "retico.ai",
#   "industries": [
#     "Artificial Intelligence"
#   ],
#   "employee_count_estimate": {
#     "min": 500,
#     "max": 1000
#   },
#   "hq_location": {
#     "city": "New York",
#     "country": "USA"
#   },
#   "founded_year": 2015,
#   "tech_stack": [
#     "Python",
#     "AWS",
#     "Docker"
#   ],
#   "social_metrics": {
#     "followers": {
#       "linkedin": 5000,
#       "twitter": 3000
#     }
#   },
#   "source_urls": [
#     "https://linkedin.com/company/retico"
#   ],
#   "last_scraped": {
#     "$date": "2025-07-28T12:00:00.000Z"
#   },
#   "last_scored": {
#     "$date": "2025-07-27T12:00:00.000Z"
#   },
#   "last_vectorized": {
#     "$date": "2025-08-04T10:32:19.644Z"
#   },
#   "changed_at": {
#     "$date": "2025-07-28T12:00:00.000Z"
#   },
#   "icp_id": {
#     "$oid": "64c4a23b69a84f2b0b789ce2"
#   },
#   "icp_version": 3
# }
#--------------------------------------------------------------------


# ACtual code:
WEIGHTS = {
    "industry": 20,
    "employee_count": 15,
    "location": 15,
    "tech_stack": 25,
    "keywords": 10,
    "founded_year": 5,
    "github_signal": 10
}
 
# --- 1. Get latest active ICP ---
latest_icp = list(icp_profiles.aggregate(pipeline))
 
if not latest_icp:
    print("‚ùå No active ICP found.")
    exit()
icp = latest_icp[0]
icp_id = str(icp["_id"])
icp_version = icp.get("version", 1)
 
# --- 2. Get ICP vector from Qdrant ---
 
icp_vector_resp = qdrant.retrieve(
    collection_name="icp_vectors",
    ids= [str(uuid.uuid5(uuid.NAMESPACE_DNS, f"icp:{icp_id}"))],
    with_vectors=True
)
 
if not icp_vector_resp or not icp_vector_resp[0].vector:
    print("‚ùå ICP vector not found.")
    exit()
 
icp_embedding = icp_vector_resp[0].vector
 
# --- 3. Get all company vectors from Qdrant ---
search_result = qdrant.query_points(
    collection_name="company_vectors",
    query=icp_embedding,
    limit=10000,
    with_payload=True,
    with_vectors=True
)
print(f"Total points returned from Qdrant: {len(search_result.points)}")
 
# icp_founded_after = icp.get("filters", {}).get("founded_after", 2015)
 
# --- 4. Scoring Rule Function () ---
def rule_score(company_doc, icp_tokens, icp_field_tokens):
    rule_score = 0
    breakdown = {k: 0 for k in WEIGHTS}
    def safe_list(field):
        value = company_doc.get(field, [])
        if isinstance(value, str): return [value]
        if isinstance(value, list): return value
        return []
    
    # Match tokens in industry, location, tech stack, keywords
    for field, key in [("industries", "industry"), ("hq_location", "location"),
                       ("tech_stack", "tech_stack"), ("keywords", "keywords")]:
        values = (
            safe_list(field) if field != "hq_location"
            else list(company_doc.get("hq_location", {}).values())
        )
        if any(token in str(v).lower() for v in values for token in icp_tokens):
            rule_score += WEIGHTS[key]
            breakdown[key] = WEIGHTS[key]
 
    # Match employee count
    emp = company_doc.get("employee_count_estimate", {})
    if emp.get("min", 0) >= 10 and emp.get("max", 0) <= 500:
        rule_score += WEIGHTS["employee_count"]
        breakdown["employee_count"] = WEIGHTS["employee_count"]
 
    # Founded year match
    if isinstance(company_doc.get("founded_year"), int) and company_doc["founded_year"] >= icp_field_tokens.get("founded_after") :
        rule_score += WEIGHTS["founded_year"]
        breakdown["founded_year"] = WEIGHTS["founded_year"]
 
    # GitHub presence
    urls = company_doc.get("source_urls", [])
    if any("github" in url.lower() for url in urls):
        rule_score += WEIGHTS["github_signal"]
        breakdown["github_signal"] = WEIGHTS["github_signal"]
 
    return rule_score, breakdown
 
# --- 5. Tokenize ICP filters ---
icp_filters = icp.get('filters', {})
icp_tokens =[]
icp_field_tokens = {}

# extract industry tokens
for field_name in ['industry', 'industries']:
    if field_name in icp_filters:
        industries = icp_filters[field_name]
        if isinstance(industries, list):
            for industry in industries:
                tokens = str(industry).lower().split()
                icp_tokens.extend(tokens)
        elif isinstance(industries, str):
            tokens = industries.lower().split()
            icp_tokens.extend(tokens)

# Extract tech stack tokens
if 'tech_stack' in icp_filters:
    tech_stack = icp_filters['tech_stack']
    if isinstance(tech_stack, list):
        for tech in tech_stack:
            # Keep full tech names for exact matching
            icp_tokens.append(str(tech).lower())
    elif isinstance(tech_stack, str):
        icp_tokens.append(tech_stack.lower())
 
# Extract keyword tokens
if 'keywords' in icp_filters:
    keywords = icp_filters['keywords']
    if isinstance(keywords, list):
        for keyword in keywords:
            icp_tokens.append(str(keyword).lower())
    elif isinstance(keywords, str):
        icp_tokens.append(keywords.lower())


# Extract location tokens
for field_name in ['location', 'locations']:
    if field_name in icp_filters:
        locations = icp_filters[field_name]
        if isinstance(locations, list):
            for location in locations:
                tokens = str(location).lower().split()
                icp_tokens.extend(tokens)
        elif isinstance(locations, str):
            tokens = locations.lower().split()
            icp_tokens.extend(tokens)



# Employee count
if 'employee_count' in icp_filters:
    emp_filter = icp_filters['employee_count']
    if isinstance(emp_filter, dict):
        icp_field_tokens['employee_count'] = emp_filter  # keep structured for later numeric match
        if 'min' in emp_filter:
            icp_tokens.append(f"emp_min_{emp_filter['min']}")
        if 'max' in emp_filter:
            icp_tokens.append(f"emp_max_{emp_filter['max']}")

# Founded after
if 'founded_after' in icp_filters:
    founded_year = icp_filters['founded_after']
    icp_field_tokens['founded_after'] = founded_year  # keep structured
    icp_tokens.append(f"founded_after_{founded_year}")




# Clean up tokens
icp_tokens = list(set(token.strip() for token in icp_tokens if token.strip()))

print(f"‚úÖ Extracted ICP tokens: {icp_tokens}")
print(f"‚úÖ Field-specific tokens: {icp_field_tokens}")



# --- 6. Score companies using util.cos_sim() ---
scored_results_util = []
icp_tensor = torch.tensor([icp_embedding], dtype=torch.float32)  # Convert ICP to tensor

for point in search_result.points:
    payload = point.payload
    company_id = payload.get("company_id")
    company_vector = point.vector

    # Calculate cosine similarity using util.cos_sim()
    company_tensor = torch.tensor([company_vector], dtype=torch.float32)
    raw_similarity = util.cos_sim(icp_tensor, company_tensor)[0][0].item()
    vector_similarity_score = ((raw_similarity + 1) / 2) * 100  # Normalize to 0‚Äì100

    try:
        if isinstance(company_id, str):
            company_id = ObjectId(company_id)
    except Exception as e:
        print(f'{company_id} has invalid ObjectId: {e}')
        continue 

    company = discovered_companies.find_one({"_id": company_id})
    if not company:
        continue

    # Apply rule-based scoring
    rule_score_total, breakdown = rule_score(company, icp_tokens, icp_field_tokens)
    print("\n",breakdown)
    print(rule_score)
    # Final score weights
    vector_weight = 0.4
    rule_weight = 0.6

    final_score = round(
        (vector_similarity_score * vector_weight) + (rule_score_total * rule_weight),
        2
    )

    breakdown["vector_similarity"] = round(vector_similarity_score, 2)

    scored_doc = {
        "company_id": company_id,
        "icp_id": icp_id,
        "icp_version": icp_version,
        "final_score": final_score,
        "breakdown": breakdown,
        "weights": WEIGHTS,
        "last_scored": datetime.now(timezone.utc),
        "method": "util_cos_sim"
    }

    scored_companies.update_one(
        {"company_id": company_id, "icp_id": icp_id, "method": "util_cos_sim"},
        {"$set": scored_doc},
        upsert=True
    )

    scored_results_util.append((company.get("domain", "unknown"), final_score))

# --- 7. Print Top Results ---
print(f"üìà Total companies scored: {len(scored_results_util)}")

sorted_results = sorted(scored_results_util, key=lambda x: x[1], reverse=True)

print("\nüèÜ TOP RESULTS (Weighted Average Method):")
for i, (domain, score) in enumerate(sorted_results[:10], 1):
    print(f"{i:2d}. {domain:20s} ‚Üí {score:6.2f}%")


# Result:

Total points returned from Qdrant: 5
‚úÖ Extracted ICP tokens: ['emp_min_1', 'founded_after_2019', 'usa', 'ai', 'software', 'ai, ml', 'canada', 'python', 'emp_max_500', 'aws']
‚úÖ Field-specific tokens: {'employee_count': {'min': 1, 'max': 500}, 'founded_after': 2019}

 {'industry': 0, 'employee_count': 15, 'location': 15, 'tech_stack': 25, 'keywords': 0, 'founded_year': 5, 'github_signal': 0}
<function rule_score at 0x7717ca1b7640>

 {'industry': 0, 'employee_count': 0, 'location': 15, 'tech_stack': 25, 'keywords': 0, 'founded_year': 0, 'github_signal': 0}
<function rule_score at 0x7717ca1b7640>

 {'industry': 0, 'employee_count': 15, 'location': 15, 'tech_stack': 25, 'keywords': 0, 'founded_year': 5, 'github_signal': 0}
<function rule_score at 0x7717ca1b7640>

 {'industry': 20, 'employee_count': 0, 'location': 15, 'tech_stack': 25, 'keywords': 0, 'founded_year': 5, 'github_signal': 0}
<function rule_score at 0x7717ca1b7640>

 {'industry': 0, 'employee_count': 15, 'location': 15, 'tech_stack': 25, 'keywords': 0, 'founded_year': 0, 'github_signal': 0}
<function rule_score at 0x7717ca1b7640>
üìà Total companies scored: 5

üèÜ TOP RESULTS (Weighted Average Method):
 1. flowcast.ai          ‚Üí  71.51%
 2. neogencloud.com      ‚Üí  69.71%
 3. ssynthai.io          ‚Üí  69.59%
 4. ddocstream.com       ‚Üí  59.94%
 5. retico.ai            ‚Üí  58.62%